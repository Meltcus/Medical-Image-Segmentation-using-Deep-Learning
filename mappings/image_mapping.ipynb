{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9790462,"sourceType":"datasetVersion","datasetId":5999150}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:18:10.614696Z","iopub.execute_input":"2024-12-09T00:18:10.615419Z","iopub.status.idle":"2024-12-09T00:18:10.619862Z","shell.execute_reply.started":"2024-12-09T00:18:10.615387Z","shell.execute_reply":"2024-12-09T00:18:10.619056Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Set Paths & Configs","metadata":{}},{"cell_type":"code","source":"excel_path = '/kaggle/input/huron-dataset/image_class_mapping.xlsx'\nmasks_dir = '/kaggle/input/huron-dataset/Sliced_masks' \nmapped_df = pd.read_excel(excel_path)\n\n#verify dataset count\nprint(f\"Total mapped images: {len(mapped_df)}\")\nprint(mapped_df.head())\n\n#GPU configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:18:12.949446Z","iopub.execute_input":"2024-12-09T00:18:12.949926Z","iopub.status.idle":"2024-12-09T00:18:13.015058Z","shell.execute_reply.started":"2024-12-09T00:18:12.949874Z","shell.execute_reply":"2024-12-09T00:18:13.014172Z"}},"outputs":[{"name":"stdout","text":"Total mapped images: 995\n    Image                                  Class\n0  18.png  Preview Tiles Small Fragmented tissue\n1  19.png  Preview Tiles Small Fragmented tissue\n2  20.png  Preview Tiles Small Fragmented tissue\n3  21.png  Preview Tiles Small Fragmented tissue\n4  22.png  Preview Tiles Small Fragmented tissue\nUsing device: cuda\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Prepocessing Data","metadata":{}},{"cell_type":"markdown","source":"### Splitting Dataset","metadata":{}},{"cell_type":"code","source":"all_mask_files = os.listdir(masks_dir)\n\n#separate mapped and unmapped masks\nunmapped_files = [f for f in all_mask_files if f not in mapped_df['Image'].values]\n\n#split mapped dataset\ntrain_mapped, test_mapped = train_test_split(\n    mapped_df, test_size=0.2, random_state=42, stratify=mapped_df['Class'])\n\n#split sizes\nprint(f\"Training Mapped: {len(train_mapped)}, Test Mapped: {len(test_mapped)}\")\nprint(f\"Unmapped Files: {len(unmapped_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:18:16.832211Z","iopub.execute_input":"2024-12-09T00:18:16.832581Z","iopub.status.idle":"2024-12-09T00:18:17.307839Z","shell.execute_reply.started":"2024-12-09T00:18:16.832553Z","shell.execute_reply":"2024-12-09T00:18:17.306951Z"}},"outputs":[{"name":"stdout","text":"Training Mapped: 796, Test Mapped: 199\nUnmapped Files: 16352\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Dataset Class","metadata":{}},{"cell_type":"code","source":"#We create a datset class to help load and preprocess data\n\nclass MaskDataset(Dataset):\n    def __init__(self, dataframe, masks_dir, transform=None):\n        self.dataframe = dataframe\n        self.masks_dir = masks_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        mask_path = os.path.join(self.masks_dir, row['Image'])\n        mask = np.array(Image.open(mask_path).convert(\"L\")) #grayscale\n        label = row['Class']\n\n        if self.transform:\n            mask = self.transform(mask)\n\n        return mask, label\n\n#transform the masks\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Normalize(mean=[0.485], std=[0.229]),\n    transforms.Lambda(lambda x: x.repeat(3, 1, 1))])\n\n#split the datasets\ntrain_dataset = MaskDataset(train_mapped, masks_dir, transform)\ntest_dataset = MaskDataset(test_mapped, masks_dir, transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:18:21.577281Z","iopub.execute_input":"2024-12-09T00:18:21.577592Z","iopub.status.idle":"2024-12-09T00:18:21.585560Z","shell.execute_reply.started":"2024-12-09T00:18:21.577567Z","shell.execute_reply":"2024-12-09T00:18:21.584595Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Model Setup & Training","metadata":{}},{"cell_type":"markdown","source":"### Setup","metadata":{}},{"cell_type":"code","source":"#loading the model\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = models.resnet50(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(mapped_df['Class'].unique())) #gets the length of each unique class which is 7\nmodel = model.to(device)\nmodel = torch.nn.DataParallel(model) #We are going to enable DataParallel to make use of kaggle's dual GPUs(T4).\n\n#loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.0001,weight_decay=0.0)\n\n#model summary\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:18:26.476613Z","iopub.execute_input":"2024-12-09T00:18:26.477299Z","iopub.status.idle":"2024-12-09T00:18:27.717343Z","shell.execute_reply.started":"2024-12-09T00:18:26.477267Z","shell.execute_reply":"2024-12-09T00:18:27.716389Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 173MB/s]\n","output_type":"stream"},{"name":"stdout","text":"DataParallel(\n  (module): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=7, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nunique_classes = set()\nfor _, labels in train_loader:\n    unique_classes.update(labels)\n    \nclass_to_int = {cls: idx for idx, cls in enumerate(unique_classes)}\nint_to_class = {idx: cls for cls, idx in class_to_int.items()}\n\ndef train_model(model, train_loader, test_loader, criterion, optimizer, epochs=None):\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in tqdm(train_loader):\n            labels = [class_to_int[label] for label in labels]\n            inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f\"Epoch {epoch + 1}, Training Loss: {running_loss / len(train_loader)}\")\n\n        #call test\n        test_model(model, test_loader, criterion)\n\ndef test_model(model, test_loader, criterion):\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            labels = [class_to_int[label] for label in labels]\n            inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f\"Test Loss: {test_loss / len(test_loader)}, Accuracy: {100 * correct / total}%\")\n\n#Train the model\ntrain_model(model, train_loader, test_loader, criterion, optimizer, epochs=22)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:31:22.082743Z","iopub.execute_input":"2024-12-09T00:31:22.083540Z","iopub.status.idle":"2024-12-09T00:35:48.464583Z","shell.execute_reply.started":"2024-12-09T00:31:22.083508Z","shell.execute_reply":"2024-12-09T00:35:48.463663Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Training Loss: 0.04879610908217728\nTest Loss: 0.6229245009330603, Accuracy: 84.42211055276383%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Training Loss: 0.05620527969906106\nTest Loss: 0.6206578775667227, Accuracy: 87.43718592964824%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Training Loss: 0.04416210222989321\nTest Loss: 0.45146862195374876, Accuracy: 90.95477386934674%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Training Loss: 0.04680671736365184\nTest Loss: 0.6511748627974436, Accuracy: 88.44221105527639%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Training Loss: 0.03509345697239041\nTest Loss: 0.4371964131983427, Accuracy: 90.45226130653266%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Training Loss: 0.040776352728717026\nTest Loss: 0.5536113668662997, Accuracy: 89.44723618090453%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Training Loss: 0.06047896529082209\nTest Loss: 0.5976255387067795, Accuracy: 87.43718592964824%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Training Loss: 0.11822748314589263\nTest Loss: 0.6455268395634798, Accuracy: 83.41708542713567%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Training Loss: 0.08353885956574231\nTest Loss: 0.6718590609156169, Accuracy: 84.42211055276383%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Training Loss: 0.10843266671523452\nTest Loss: 1.1789498627185822, Accuracy: 75.37688442211055%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Training Loss: 0.07320373735390603\nTest Loss: 0.6611417483251828, Accuracy: 85.42713567839196%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Training Loss: 0.06553415951319039\nTest Loss: 0.548593496473936, Accuracy: 87.43718592964824%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Training Loss: 0.03485669936402701\nTest Loss: 0.6347189276264265, Accuracy: 85.92964824120602%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Training Loss: 0.03699510023812763\nTest Loss: 0.8034522304168115, Accuracy: 86.4321608040201%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Training Loss: 0.05129243897274136\nTest Loss: 0.6490065545703356, Accuracy: 87.43718592964824%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16, Training Loss: 0.04753495764569379\nTest Loss: 0.5928940089562764, Accuracy: 86.93467336683418%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17, Training Loss: 0.03555901162559166\nTest Loss: 0.5549720643231502, Accuracy: 88.44221105527639%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18, Training Loss: 0.032342234743991866\nTest Loss: 0.5672657249065546, Accuracy: 87.93969849246231%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19, Training Loss: 0.028577275122515858\nTest Loss: 0.539278135706599, Accuracy: 88.44221105527639%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20, Training Loss: 0.02641967629431747\nTest Loss: 0.5120312485557336, Accuracy: 88.94472361809045%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21, Training Loss: 0.029387922687456013\nTest Loss: 0.5077387710603384, Accuracy: 88.44221105527639%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:10<00:00,  4.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22, Training Loss: 0.028872970604570582\nTest Loss: 0.5406551597138437, Accuracy: 87.93969849246231%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Predict Classes","metadata":{}},{"cell_type":"code","source":"def predict_unmapped_masks(model, unmapped_files, masks_dir, transform, int_to_class, output_path=\"mapped_results.xlsx\"):\n    model.eval()\n    predictions = []\n    confidence_scores = []\n\n    for file in tqdm(unmapped_files):\n        mask_path = os.path.join(masks_dir, file)\n        mask = np.array(Image.open(mask_path).convert(\"L\"))\n        if transform:\n            mask = transform(mask).unsqueeze(0).to(device)\n\n        with torch.no_grad():\n            outputs = model(mask)\n            probs = torch.softmax(outputs, dim=1)\n            confidence, predicted = torch.max(probs, 1)\n            predictions.append(predicted.item())\n            confidence_scores.append(confidence.item())\n\n    predicted_classes = [int_to_class[p] for p in predictions]\n\n    #confidence levels\n    confidence_categories = ['High' if c >= 0.7 else 'Medium' if c >= 0.45 else 'Low' for c in confidence_scores]\n\n    #output structure\n    output_df = pd.DataFrame({\n        'Image': unmapped_files,\n        'Predicted Class': predicted_classes,\n        'Confidence Score': confidence_scores,\n        'Confidence Category': confidence_categories\n    })\n\n    output_df.to_excel(output_path, index=False)\n    print(f\"Output saved to {output_path}\")\n\n#find predictions\npredict_unmapped_masks(model, unmapped_files, masks_dir, transform,int_to_class)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T00:37:47.693410Z","iopub.execute_input":"2024-12-09T00:37:47.693743Z","iopub.status.idle":"2024-12-09T00:45:16.517129Z","shell.execute_reply.started":"2024-12-09T00:37:47.693718Z","shell.execute_reply":"2024-12-09T00:45:16.516206Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 16352/16352 [07:27<00:00, 36.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Output saved to mapped_results.xlsx\n","output_type":"stream"}],"execution_count":20}]}
