{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9790462,"sourceType":"datasetVersion","datasetId":5999150}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"#Run this cell if you are using collab.\n!pip install opendatasets\n!pip install pandas","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:13:38.954869Z","iopub.execute_input":"2024-12-07T06:13:38.955247Z","iopub.status.idle":"2024-12-07T06:13:57.145649Z","shell.execute_reply.started":"2024-12-07T06:13:38.955213Z","shell.execute_reply":"2024-12-07T06:13:57.144666Z"}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\nCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.26.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.3.0)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\nCollecting timm==0.9.7 (from segmentation-models-pytorch)\n  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.0)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nDownloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=fc8359214a8950bfe4ae05978568195d96142db46db0580c0bbd0b7714b7f428\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=f3dd1801b9af2ac696c872bc87753c983bf037a17b5d602a5ea0d8703199d80c\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.11\n    Uninstalling timm-1.0.11:\n      Successfully uninstalled timm-1.0.11\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom pathlib import Path\nimport numpy as np\nfrom tqdm import tqdm\nimport segmentation_models_pytorch as smp\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:14.666034Z","iopub.execute_input":"2024-12-07T06:14:14.666372Z","iopub.status.idle":"2024-12-07T06:14:14.671768Z","shell.execute_reply.started":"2024-12-07T06:14:14.666327Z","shell.execute_reply":"2024-12-07T06:14:14.670871Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Class Definitions","metadata":{}},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"class HuronDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None):\n        self.image_dir = Path(image_dir)\n        self.mask_dir = Path(mask_dir)\n        self.transform = transform\n        self.mask_transform = transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor()\n        ])\n        self.images = sorted(os.listdir(image_dir))\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.image_dir / self.images[idx]\n        mask_path = self.mask_dir / self.images[idx]\n\n        image = Image.open(img_path).convert('RGB')\n        mask = Image.open(mask_path).convert('L')\n\n        if self.transform:\n            image = self.transform(image)\n        mask = self.mask_transform(mask)\n\n        # Ensure mask is binary\n        mask = (mask > 0.5).float()\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:19.324908Z","iopub.execute_input":"2024-12-07T06:14:19.325235Z","iopub.status.idle":"2024-12-07T06:14:19.331871Z","shell.execute_reply.started":"2024-12-07T06:14:19.325206Z","shell.execute_reply":"2024-12-07T06:14:19.331028Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Eval Metrics","metadata":{}},{"cell_type":"code","source":"def calculate_iou(outputs, targets, threshold=0.5):\n    outputs = (outputs > threshold).float()\n    targets = targets.float()\n\n    intersection = (outputs * targets).sum(dim=(1, 2))\n    union = outputs.sum(dim=(1, 2)) + targets.sum(dim=(1, 2)) - intersection\n\n    iou = (intersection + 1e-6) / (union + 1e-6)\n    return iou.mean()\n\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    total_iou = 0\n    num_batches = len(dataloader)\n\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            masks = masks.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, masks)\n            iou = calculate_iou(outputs, masks)\n\n            total_loss += loss.item()\n            total_iou += iou.item()\n\n    return total_loss / num_batches, total_iou / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:24.871033Z","iopub.execute_input":"2024-12-07T06:14:24.871397Z","iopub.status.idle":"2024-12-07T06:14:24.877909Z","shell.execute_reply.started":"2024-12-07T06:14:24.871367Z","shell.execute_reply":"2024-12-07T06:14:24.877064Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n    best_val_iou = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        running_iou = 0.0\n\n        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n            for images, masks in pbar:\n                images = images.to(device)\n                masks = masks.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, masks)\n                iou = calculate_iou(outputs, masks)\n\n                loss.backward()\n                optimizer.step()\n\n                running_loss += loss.item()\n                running_iou += iou.item()\n\n                pbar.set_postfix({\n                    'loss': running_loss / (pbar.n + 1),\n                    'IoU': running_iou / (pbar.n + 1)\n                })\n\n        # Validate\n        model.eval()\n        val_iou = 0\n        with torch.no_grad():\n            for images, masks in val_loader:\n                images = images.to(device)\n                masks = masks.to(device)\n                outputs = model(images)\n                val_iou += calculate_iou(outputs, masks).item()\n\n        val_iou /= len(val_loader)\n        print(f'Validation IoU: {val_iou:.4f}')\n\n        if val_iou > best_val_iou:\n            best_val_iou = val_iou\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:28.241715Z","iopub.execute_input":"2024-12-07T06:14:28.242546Z","iopub.status.idle":"2024-12-07T06:14:28.253808Z","shell.execute_reply.started":"2024-12-07T06:14:28.242497Z","shell.execute_reply":"2024-12-07T06:14:28.252911Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Visualization","metadata":{}},{"cell_type":"code","source":"def visualize_results(model, test_loader, device, num_images=3):\n    model.eval()\n\n    # Get some test images\n    test_images, test_masks = next(iter(test_loader))\n\n    with torch.no_grad():\n        test_images = test_images.to(device)\n        predictions = model(test_images)\n        predictions = (predictions > 0.5).float()\n\n    # Convert tensors to numpy for visualization\n    test_images = test_images.cpu()\n    test_masks = test_masks.cpu()\n    predictions = predictions.cpu()\n\n    # Plot results\n    fig, axes = plt.subplots(num_images, 3, figsize=(15, 5*num_images))\n\n    for idx in range(num_images):\n        # Original image\n        img = test_images[idx].permute(1, 2, 0)\n        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n        img = img.numpy()\n        img = np.clip(img, 0, 1)\n\n        # Ground truth mask\n        mask = test_masks[idx].squeeze().numpy()\n\n        # Predicted mask\n        pred = predictions[idx].squeeze().numpy()\n\n        # Plot\n        axes[idx, 0].imshow(img)\n        axes[idx, 0].set_title('Original Image')\n        axes[idx, 0].axis('off')\n\n        axes[idx, 1].imshow(mask, cmap='gray')\n        axes[idx, 1].set_title('Ground Truth Mask')\n        axes[idx, 1].axis('off')\n\n        axes[idx, 2].imshow(pred, cmap='gray')\n        axes[idx, 2].set_title('Predicted Mask')\n        axes[idx, 2].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:34.489547Z","iopub.execute_input":"2024-12-07T06:14:34.490249Z","iopub.status.idle":"2024-12-07T06:14:34.497813Z","shell.execute_reply.started":"2024-12-07T06:14:34.490218Z","shell.execute_reply":"2024-12-07T06:14:34.496988Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Loss Metric","metadata":{}},{"cell_type":"code","source":"class CombinedLoss(nn.Module):\n    def __init__(self, loss1, loss2, weight1=1.0, weight2=1.0):\n        super(CombinedLoss, self).__init__()\n        self.loss1 = loss1\n        self.loss2 = loss2\n        self.weight1 = weight1\n        self.weight2 = weight2\n\n    def forward(self, y_pred, y_true):\n        return self.weight1 * self.loss1(y_pred, y_true) + self.weight2 * self.loss2(y_pred, y_true)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:38.480382Z","iopub.execute_input":"2024-12-07T06:14:38.481171Z","iopub.status.idle":"2024-12-07T06:14:38.486034Z","shell.execute_reply.started":"2024-12-07T06:14:38.481138Z","shell.execute_reply":"2024-12-07T06:14:38.484953Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"### Kaggle Setup (2xT4 GPUs)\nSince we have dual GPUs, we encorporated Parallel Training.","metadata":{}},{"cell_type":"code","source":"import random\nimport csv\nimport wandb\nfrom pathlib import Path\n\ndef run_tuning_kaggle():\n    #We use WandB to help keep track of and analyze the tunning\n    wandb.init(project=\"huron_tuning_kaggle\", mode=\"offline\") #initialize WandB\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    #Set the paths\n    image_dir = '/kaggle/input/huron-dataset/Sliced_Images'\n    mask_dir = '/kaggle/input/huron-dataset/Sliced_masks'\n\n    #Transform the images\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])])\n\n    # Create full dataset\n    full_dataset = HuronDataset(image_dir, mask_dir, transform=transform)\n\n    # Calculate splits\n    total_size = len(full_dataset)\n    train_size = int(0.7 * total_size)\n    val_size = int(0.15 * total_size)\n    test_size = total_size - train_size - val_size\n\n    # Split dataset\n    train_dataset, val_dataset, test_dataset = random_split(\n        full_dataset,\n        [train_size, val_size, test_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n\n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n\n    #Here we define the search space for the tuning.\n    search_space = {\n        \"learning_rate\": [1e-4, 5e-4, 1e-3],\n        \"weight_decay\": [0.0, 0.01, 0.1],\n        \"batch_size\": [8, 16, 32],\n        \"num_epochs\": [10, 15, 20]}\n\n    #Setup an excel file to store our logs.\n    log_path = Path('./kaggle_results/tuning_log.csv')\n    log_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(log_path, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"trial_id\", \"learning_rate\", \"batch_size\", \"weight_decay\",\"num_epochs\", \"test_loss\", \"test_iou\"])\n\n    #We perform tuning by randomly picking the search space.\n    num_trials = 20\n    for trial_id in range(1, num_trials + 1):\n        lr = random.choice(search_space[\"learning_rate\"])\n        wd = random.choice(search_space[\"weight_decay\"])\n        batch_size = random.choice(search_space[\"batch_size\"])\n        num_epochs = random.choice(search_space[\"num_epochs\"])\n\n        #Update WandB config\n        wandb.config.update({\"trial_id\": trial_id, \"learning_rate\": lr, \"weight_decay\": wd, \"batch_size\": batch_size,\"num_epochs\": num_epochs})\n\n        #Update the dataloaders with new batch size\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n        test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n        # Initialize U-Net++\n        model = smp.UnetPlusPlus(\n            encoder_name=\"efficientnet-b4\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1\n        ).to(device)\n\n        #We are going to enable DataParallel to make use of kaggle's dual GPUs(T4).\n        model = torch.nn.DataParallel(model)\n\n        # Initialize loss and optimizer\n        criterion = CombinedLoss(\n            smp.losses.DiceLoss(mode='binary'),\n            nn.BCEWithLogitsLoss()\n        )\n        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n\n        #Set up Trial\n        print(f\"Trial {trial_id}: LR={lr}, Batch Size={batch_size}, Weight Decay={wd}, Epochs={num_epochs}\")\n        best_test_iou = 0 #holds the best iou found through the epochs.\n        patience = 2  #stops epochs when IoU stops improving after 2 iterations.\n        no_improve_epochs = 0 #stores the count at which IoU is not improving.\n\n        for epoch in range(3, num_epochs + 1):\n            print(f\"Number of Epochs:{epoch}\")\n            # Train and validate model\n            train_model(model, train_loader, val_loader, criterion, optimizer, device,num_epochs=epoch)\n            # Evaluate on Test set\n            test_loss, test_iou = evaluate(model, test_loader, criterion, device)\n            if test_iou > best_test_iou:\n                best_test_iou = test_iou\n                no_improve_epochs = 0\n            else:\n                no_improve_epochs += 1\n\n            if no_improve_epochs >= patience:\n                print(\"Early stopping triggered.\")\n                break\n        \n        print(f\"Trial {trial_id} Results: Test Loss={test_loss:.4f}, Test IoU={best_test_iou:.4f}\")\n\n        #Log results to WandB and Excel file\n        wandb.log({\"test_loss\": test_loss, \"test_iou\": best_test_iou})\n        with open(log_path, mode='a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([trial_id, lr, batch_size, wd,num_epochs, test_loss, best_test_iou])\n\n    print(\"Tuning complete. Results saved to:\", log_path)\n\n#this runs the function\nif __name__ == \"__main__\":\n    run_tuning_kaggle()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T06:14:44.391507Z","iopub.execute_input":"2024-12-07T06:14:44.391929Z","iopub.status.idle":"2024-12-07T06:15:14.957824Z","shell.execute_reply.started":"2024-12-07T06:14:44.391851Z","shell.execute_reply":"2024-12-07T06:15:14.956515Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n100%|██████████| 74.4M/74.4M [00:00<00:00, 229MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Trial 1: LR=0.0001, Batch Size=32, Weight Decay=0.01, Epochs=10\nNumber of Epochs:3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3:   0%|          | 0/380 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\nEpoch 1/3:   8%|▊         | 30/380 [00:26<05:05,  1.15it/s, loss=1.06, IoU=0.427]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 127\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#this runs the function\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mrun_tuning_kaggle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[9], line 102\u001b[0m, in \u001b[0;36mrun_tuning_kaggle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Epochs:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Train and validate model\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Evaluate on Test set\u001b[39;00m\n\u001b[1;32m    104\u001b[0m test_loss, test_iou \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n","Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, masks)\n\u001b[1;32m     17\u001b[0m iou \u001b[38;5;241m=\u001b[39m calculate_iou(outputs, masks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 185\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:190\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: T, device_ids: Sequence[Union[\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T]:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:134\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m    132\u001b[0m module_indices[module] \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_replicas):\n\u001b[0;32m--> 134\u001b[0m     replica \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replicate_for_data_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# This is a temporary fix for DDP. DDP needs to access the\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# replicated model parameters. It used to do so through\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# `mode.parameters()`. The fix added in #33907 for DP stops the\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# `parameters()` API from exposing the replicated parameters.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Hence, we add a `_former_parameters` dict here to support DDP.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     replica\u001b[38;5;241m.\u001b[39m_former_parameters \u001b[38;5;241m=\u001b[39m OrderedDict()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2587\u001b[0m, in \u001b[0;36mModule._replicate_for_data_parallel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m replica\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;66;03m# replicas do not have parameters themselves, the replicas reference the original\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 2587\u001b[0m \u001b[43mreplica\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   2588\u001b[0m replica\u001b[38;5;241m.\u001b[39m_buffers \u001b[38;5;241m=\u001b[39m replica\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2589\u001b[0m replica\u001b[38;5;241m.\u001b[39m_modules \u001b[38;5;241m=\u001b[39m replica\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mcopy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1754\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(name, value)\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1754\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_modules\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Module):\n\u001b[1;32m   1756\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"### Colab Setup (A100 GPU)\nSince we are using a much stringer GPU, higher batch sizes have been used to train our model.","metadata":{}},{"cell_type":"code","source":"import random\nimport csv\nimport wandb\nfrom pathlib import Path\n\ndef run_tuning_colab():\n    # We use WandB to help keep track of and analyze the tuning\n    wandb.init(project=\"huron_tuning_colab\", mode=\"offline\")  # Initialize WandB\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n\n    # Set the paths\n    image_dir = '/content/huron-dataset/Sliced_Images'\n    mask_dir = '/content/huron-dataset/Sliced_masks'\n\n    # Transform the images\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])])\n\n    # Create full dataset\n    full_dataset = HuronDataset(image_dir, mask_dir, transform=transform)\n\n    # Calculate splits\n    total_size = len(full_dataset)\n    train_size = int(0.7 * total_size)\n    val_size = int(0.15 * total_size)\n    test_size = total_size - train_size - val_size\n\n    # Split dataset\n    train_dataset, val_dataset, test_dataset = random_split(\n        full_dataset,\n        [train_size, val_size, test_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n\n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n\n    # Here we define the search space for the tuning\n    search_space = {\n        \"learning_rate\": [5e-5, 1e-4, 5e-4],\n        \"weight_decay\": [0.0, 0.01, 0.1],\n        \"batch_size\": [16, 32, 64],\n        \"num_epochs\": [10, 15, 20]}\n\n    # Setup an excel file to store our logs\n    log_path = Path('./colab_results/tuning_log.csv')\n    log_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(log_path, mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"trial_id\", \"learning_rate\", \"batch_size\", \"weight_decay\", \"num_epochs\", \"test_loss\", \"test_iou\"])\n\n    # We perform tuning by randomly picking the search space\n    num_trials = 20\n    for trial_id in range(1, num_trials + 1):\n        lr = random.choice(search_space[\"learning_rate\"])\n        wd = random.choice(search_space[\"weight_decay\"])\n        batch_size = random.choice(search_space[\"batch_size\"])\n        num_epochs = random.choice(search_space[\"num_epochs\"])\n\n        # Update WandB config\n        wandb.config.update({\"trial_id\": trial_id, \"learning_rate\": lr, \"weight_decay\": wd, \"batch_size\": batch_size, \"num_epochs\": num_epochs})\n\n        # Update the dataloaders with new batch size\n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n        # Initialize U-Net++\n        model = smp.UnetPlusPlus(\n            encoder_name=\"efficientnet-b4\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1\n        ).to(device)\n\n        # Single GPU setup, no DataParallel needed\n        print(f\"Trial {trial_id}: LR={lr}, Batch Size={batch_size}, Weight Decay={wd}, Epochs={num_epochs}\")\n        best_test_iou = 0  # Holds the best IoU found through the epochs\n        patience = 2  # Stops epochs when IoU stops improving after 2 iterations\n        no_improve_epochs = 0  # Stores the count at which IoU is not improving\n\n        for epoch in range(3, num_epochs + 1):\n            print(f\"Number of Epochs: {epoch}\")\n            # Train and validate model\n            train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=epoch)\n            # Evaluate on Test set\n            test_loss, test_iou = evaluate(model, test_loader, criterion, device)\n            if test_iou > best_test_iou:\n                best_test_iou = test_iou\n                no_improve_epochs = 0\n            else:\n                no_improve_epochs += 1\n\n            if no_improve_epochs >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n        print(f\"Trial {trial_id} Results: Test Loss={test_loss:.4f}, Test IoU={best_test_iou:.4f}\")\n\n        # Log results to WandB and Excel file\n        wandb.log({\"test_loss\": test_loss, \"test_iou\": best_test_iou})\n        with open(log_path, mode='a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow([trial_id, lr, batch_size, wd, num_epochs, test_loss, best_test_iou])\n\n    print(\"Tuning complete. Results saved to:\", log_path)\n\n\n# This runs the function\nif __name__ == \"__main__\":\n    run_tuning_colab()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}